import argparse
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_ollama import OllamaLLM

from get_embedding_function import get_embedding_function

# Define constants for Chroma DB path and prompt template
CHROMA_PATH = "chroma"

PROMPT_TEMPLATE = """
Answer the question based only on the following context:

{context}

---

Answer the question based on the above context: {question}
"""

def main():
    """
    Main function that keeps asking the user for queries and exits when the user chooses to quit.
    """
    while True:
        # Prompt the user for input
        query_text = input("Enter your question (or type 'exit' to quit): ")
        
        # Exit the loop if the user types 'exit'
        if query_text.lower() == "exit":
            print("Goodbye!")
            break

        # Query the data based on user input
        response = query_data(query_text)
        
        # Print the response
        print("\nResponse:\n", response, "\n")

def query_data(query_text: str):
    """
    Queries the Chroma database with the given query text and returns the response.

    Args:
        query_text (str): The user's query.

    Returns:
        str: The response generated by the language model.
    """
    # Prepare the DB.
    embedding_function = get_embedding_function()
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)

    # Search the DB.
    results = db.similarity_search_with_score(query_text, k=5)

    # Prepare the context text for the prompt
    context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])
    
    # Format the prompt with context and question
    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)

    prompt = prompt_template.format(context=context_text, question=query_text)

    # Initialize the model and generate a response
    model = OllamaLLM(model="llama3.2")
    response_text = model.invoke(prompt)

    return response_text

if __name__ == "__main__":
    main()